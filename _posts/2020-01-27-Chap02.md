---
layout: post
title: "Hands on MachineLearning: Chap02 (작성중)"
date: 2020-01-27
excerpt: "Hands on MachineLearning: Chap02 (작성중)"
tags: [MachineLearning, Python]
comments: true
MathJax: true
---

# Chap02. End-to-End Machine Learning Project

이 장에서는 아래와 같은 주요 단계를 거치며 메인 프로젝트를 진행합니다.

1.   Look at the big picture.
2.   Get the data.
3.   Discover and visualize the data to gain insights.
4.   Prepare the data for Machine Learning algorithms.
5.   Select a model and train it.
6.   Fine-tune your model.
7.   Present your solution.
8.   Launch, monitor, and maintain your system.


## Working with Real Data

머신 러닝을 배울 대는 실제 데이터로 연습해 보는 것이 가장 좋습니다. 아래 책에서 소개하는 몇개의 오픈 데이터 셋 사이트와, 우리나라 공공 데이터 사이트들의 링크가 있습니다.

* 책에서 소개하는 사이트
  *   [UCL Machine Learning Repository](http://archive.ics.uci.edu/ml/index.php)
  *   [Kaggle datasets](https://www.kaggle.com/datasets)
  *   [Amozon's AWS datasets](https://registry.opendata.aws/)
* 우리나라 공공 데이터 사이트
  *   [공공 데이터 포털](https://www.data.go.kr/)
  *   [서울 열린데이터광장](https://data.seoul.go.kr/)


이 장에서는 StatLib repository의 California Hosing Prices 데이터 셋을 이용합니다. 이 데이터 셋은 1990 California 센서스 데이터에 기반을 두고 있으며, 범주형 변수를 추가하고 몇개의 변수를 삭제할 것입니다.


## Look at the Big Picture

## Get the Data

### Create the Workspace

교재에서는 파이썬을 설치하고 주피터 노트북을 이용하여 분석 환경을 만들었지만, 여기서는 google Colab을 사용하기로 합니다.


```
from google.colab import drive
drive.mount('/content/drive')
```

    Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly

    Enter your authorization code:
    ··········
    Mounted at /content/drive



```
# Import modules

import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
import pandas as pd
```

### Download the Data

[Hands on Machine Learning 깃허브](https://github.com/ageron/handson-ml2)를 통하여 데이터 파일과 주피터 노트북 코드를 다운받을 수 있습니다. 여기서는 교재와 달리 데이터를 다운 받아 구글 드라이브에 저장 후 불러와서 사용하였습니다.

### Take a Quick Look at the Data Structure



``` head() ``` 를 이용하여 데이터 프레임의 5개 행을 확인할 수 있습니다.






```
housing = pd.read_csv("/content/drive/My Drive/colab/data/housing.csv")
housing.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="0.1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-122.23</td>
      <td>37.88</td>
      <td>41.0</td>
      <td>880.0</td>
      <td>129.0</td>
      <td>322.0</td>
      <td>126.0</td>
      <td>8.3252</td>
      <td>452600.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-122.22</td>
      <td>37.86</td>
      <td>21.0</td>
      <td>7099.0</td>
      <td>1106.0</td>
      <td>2401.0</td>
      <td>1138.0</td>
      <td>8.3014</td>
      <td>358500.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-122.24</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1467.0</td>
      <td>190.0</td>
      <td>496.0</td>
      <td>177.0</td>
      <td>7.2574</td>
      <td>352100.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1274.0</td>
      <td>235.0</td>
      <td>558.0</td>
      <td>219.0</td>
      <td>5.6431</td>
      <td>341300.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1627.0</td>
      <td>280.0</td>
      <td>565.0</td>
      <td>259.0</td>
      <td>3.8462</td>
      <td>342200.0</td>
      <td>NEAR BAY</td>
    </tr>
  </tbody>
</table>
</div>



각 행은 하나의 구역을 나타내며, 총 10개의 변수(경도, 위도, 주택 중위 연식, 총 방, 인구, 가정, 중위 소득, 중위 집 값, 해안 근접)가 있습니다.

``` info() ```를 이용하여 행 개수, 변수 타입, 결측치의 개수 등의 데이터 설명을 확인할 수 있습니다.


```
housing.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 20640 entries, 0 to 20639
    Data columns (total 10 columns):
    longitude             20640 non-null float64
    latitude              20640 non-null float64
    housing_median_age    20640 non-null float64
    total_rooms           20640 non-null float64
    total_bedrooms        20433 non-null float64
    population            20640 non-null float64
    households            20640 non-null float64
    median_income         20640 non-null float64
    median_house_value    20640 non-null float64
    ocean_proximity       20640 non-null object
    dtypes: float64(9), object(1)
    memory usage: 1.6+ MB


데이터에는 20,640개의 행이 있습니다. 여기서 ```total_bedrooms``` 변수는 20433개의 non-null e데이터가 있는데 이를 통해 207개의 구역에 대한 결측치가 존재한다는 것을 알 수 있습니다. 이에 대한 처리는 나중에 할 것 입니다.

```ocean_proximity```변수만 ```object```타입인 것을 확인할 수 있습니다. ```head()```를 통해서 데이터를 확인해 본 결과 문자형, 범주형 변수 인 것을 확인할 수 있었습니다. 어떤 범주가 얼마나 많이 있는지는 ```value_counts()```를 통해서 확인할 수 있습니다. (R에서 ```table```과 유사한 기능)


```
housing['ocean_proximity'].value_counts()
```




    <1H OCEAN     9136
    INLAND        6551
    NEAR OCEAN    2658
    NEAR BAY      2290
    ISLAND           5
    Name: ocean_proximity, dtype: int64



```describe()```는 숫자형 변수들에 대한 summary를 보여주며, null값은 무시됩니다. (R에서 ```summary```와 유사한 기능)


```
housing.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="0.1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20433.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>-119.569704</td>
      <td>35.631861</td>
      <td>28.639486</td>
      <td>2635.763081</td>
      <td>537.870553</td>
      <td>1425.476744</td>
      <td>499.539680</td>
      <td>3.870671</td>
      <td>206855.816909</td>
    </tr>
    <tr>
      <th>std</th>
      <td>2.003532</td>
      <td>2.135952</td>
      <td>12.585558</td>
      <td>2181.615252</td>
      <td>421.385070</td>
      <td>1132.462122</td>
      <td>382.329753</td>
      <td>1.899822</td>
      <td>115395.615874</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-124.350000</td>
      <td>32.540000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>1.000000</td>
      <td>0.499900</td>
      <td>14999.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-121.800000</td>
      <td>33.930000</td>
      <td>18.000000</td>
      <td>1447.750000</td>
      <td>296.000000</td>
      <td>787.000000</td>
      <td>280.000000</td>
      <td>2.563400</td>
      <td>119600.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-118.490000</td>
      <td>34.260000</td>
      <td>29.000000</td>
      <td>2127.000000</td>
      <td>435.000000</td>
      <td>1166.000000</td>
      <td>409.000000</td>
      <td>3.534800</td>
      <td>179700.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>-118.010000</td>
      <td>37.710000</td>
      <td>37.000000</td>
      <td>3148.000000</td>
      <td>647.000000</td>
      <td>1725.000000</td>
      <td>605.000000</td>
      <td>4.743250</td>
      <td>264725.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>-114.310000</td>
      <td>41.950000</td>
      <td>52.000000</td>
      <td>39320.000000</td>
      <td>6445.000000</td>
      <td>35682.000000</td>
      <td>6082.000000</td>
      <td>15.000100</td>
      <td>500001.000000</td>
    </tr>
  </tbody>
</table>
</div>



데이터 특성을 확인하는 다른 방법은 ```hist()```를 이용해서 각 숫자형 변수에 대한 히스토그램을 그려보는 것입니다. 데이터 전체에 한번에 적용해도 됩니다.


```
housing.hist(bins = 50, figsize = (20, 15))
plt.show()
```


![png](/assets/img/markdown/ml-02/Chap02_24_0.png)


히스토그램을 통해 다음과 같은 사실을 알 수 있습니다.
1. 중위 소득이 USD 단위가 아닌 것을 확인 할 수 있고, 15를 초과하는 중위 소득은 15로, 0.5 미만인 중위 소득은 0.5로 처리된 것을 확인할 수 있습니다. 숫자는 10000 달러 단위로 나타내져 있습니다.
2. 주택 중위 연식과 중위 집 값 역시 범위가 제한되어 있음을 확인할 수 있습니다. 중위 집 값은 타겟 변수이기 때문에 머신 러닝 알고리즘이 제한된 값을 넘어서 학습을 할 수 없기 때문에 문제가 있을 수 있습니다. 만약 $500,000을 넘어선 값을 예측해야 한다면 주로 두 가지 선택 방안이 있습니다:
 1. 제한된 값들에 대한 적절한 라벨을 찾는다.
 2. 훈련 셋과 테스트 셋에서 이 구역들을 제외한다.
3. 변수들이 매우 다른 스케일을 가지고 있습니다.
4. 많은 히스토그램이 꼬리가 두꺼우며, 오른쪽으로 꼬리가 긴 분포를 갖고 있습니다. 추후에 종 모양의 분포를 갖도록 변환을 할 것 입니다.

### Create a Test set

이 단계에서 데이터를 일부러 나누는 것을 이상하다 생각할수도 있습니다. 하지만, 우리의 뇌는 놀라운 패턴 감지 시스템인데, 과적합$^{overfitting} $이 일어나기 쉽습니다: 테스트 셋을 보고, 겉보기에 흥미로운 패턴에 속아 특정한 종류의 머신 러닝 모델을 선택할 수도 있습니다. 이런 테스트 셋을 사용하여 일반화 오류를 추정할 때 예상치가 너무 낙관적이어서 시스템이 기대만큼 작동하지 않을 것입니다. 이것을 *데이터 스누핑* 편향$^{data~ snooping~ bias} $ 이라고 합니다.

이론적으로 테스트 셋을 만드는 것은 매우 간단합니다: 보통 데이터 셋의 20%정도의 행을 무작위로 선택하고, 그 셋을 따로 떼어놓습니다.


```
def split_train_test(data, test_ratio):
  shuffled_indices = np.random.permutation(len(data))
  test_set_size = int(len(data)*test_ratio)
  test_indices = shuffled_indices[:test_set_size]
  train_indices = shuffled_indices[test_set_size:]
  return data.iloc[train_indices], data.iloc[test_indices]
```


```
pd.cut?
```


```

```
